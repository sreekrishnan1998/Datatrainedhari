{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c371ae9b",
   "metadata": {},
   "source": [
    "1. Write a python program which searches all the product under a particular product from www.amazon.in. The\n",
    "product to be searched will be taken as input from user. For e.g. If user input is ‘guitar’. Then search for\n",
    "guitars. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab42b8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaa427d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004e06fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc22cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_name = input(\"Enter the product name to search for: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc8d38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation= driver.find_element(By.ID, \"twotabsearchtextbox\")\n",
    "designation.send_keys(product_name)\n",
    "search= driver.find_element(By.ID, \"nav-search-submit-button\")\n",
    "search.click()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc50263",
   "metadata": {},
   "source": [
    "2. In the above question, now scrape the following details of each product listed in first 3 pages of your search\n",
    "results and save it in a data frame and csv. In case if any product has less than 3 pages in search results then\n",
    "scrape all the products available under that product name. Details to be scraped are: \"Brand\n",
    "Name\", \"Name of the Product\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\" and\n",
    "“Product URL”. In case, if any of the details are missing for any of the product then replace it by “-“. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a5b352",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Get user input for the product name\n",
    "product_name = input(\"Enter the product name to search for: \")\n",
    "\n",
    "# Function to scrape product details from a page\n",
    "def scrape_product_details(page_number):\n",
    "    product_details_list = []\n",
    "\n",
    "    # Find all the products on the current page\n",
    "    products = driver.find_elements(By.XPATH, \"//div[@data-asin]\")\n",
    "\n",
    "    for product in products:\n",
    "        brand_name = product.find_element(By.XPATH, \".//span[@class='a-size-base-plus a-color-base']\").text.strip()\n",
    "        product_title_element = product.find_element(By.XPATH, \".//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "        product_name = product_title_element.text.strip()\n",
    "        product_url = product_title_element.find_element(By.XPATH, \".//ancestor::a\").get_attribute(\"href\")\n",
    "\n",
    "        price_element = product.find_element(By.XPATH, \".//span[@class='a-offscreen']\")\n",
    "        price = price_element.text.strip() if price_element else '-'\n",
    "\n",
    "        return_exchange_element = product.find_element(By.XPATH, \".//div[@class='a-row a-size-small']\")\n",
    "        return_exchange = return_exchange_element.text.strip() if return_exchange_element else '-'\n",
    "\n",
    "        expected_delivery_element = product.find_element(By.XPATH, \".//span[@class='a-text-bold']\")\n",
    "        expected_delivery = expected_delivery_element.text.strip() if expected_delivery_element else '-'\n",
    "\n",
    "        availability_element = product.find_element(By.XPATH, \".//span[@class='a-size-medium a-color-success']\")\n",
    "        availability = availability_element.text.strip() if availability_element else '-'\n",
    "\n",
    "        product_details_list.append({\n",
    "            'Brand Name': brand_name,\n",
    "            'Name of the Product': product_name,\n",
    "            'Price': price,\n",
    "            'Return/Exchange': return_exchange,\n",
    "            'Expected Delivery': expected_delivery,\n",
    "            'Availability': availability,\n",
    "\n",
    "            \n",
    "'Product URL': product_url\n",
    "        })\n",
    "\n",
    "    return product_details_list\n",
    "\n",
    "# Loop through the first three pages\n",
    "for page_number in range(1, 4):\n",
    "    url = f'https://www.amazon.in/s?k={product_name}&page={page_number}'\n",
    "\n",
    "    # Navigate to the search results page\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for the search results to load\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//div[@data-asin]\")))\n",
    "\n",
    "    # Scrape product details for the current page\n",
    "    product_details = scrape_product_details(page_number)\n",
    "\n",
    "    # Create a DataFrame from the scraped data\n",
    "    df = pd.DataFrame(product_details)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(f'{product_name}_search_results_page_{page_number}.csv', index=False)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537590e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab22bff1",
   "metadata": {},
   "source": [
    "3. Write a python program to access the search bar and search button on images.google.com and scrape 10\n",
    "images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’, ‘Guitar’, ‘Cakes’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c79434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Keywords\n",
    "keywords = ['fruits', 'cars', 'Machine Learning', 'Guitar', 'Cakes']\n",
    "\n",
    "# Loop through each keyword\n",
    "for keyword in keywords:\n",
    "    # Navigate to Google Images\n",
    "    driver.get(\"https://images.google.com/\")\n",
    "\n",
    "    # Find the search bar\n",
    "    search_bar = driver.find_element(\"name\", \"q\")\n",
    "\n",
    "    # Enter the keyword and press Enter\n",
    "    search_bar.send_keys(keyword)\n",
    "    search_bar.send_keys(Keys.RETURN)\n",
    "\n",
    "    # Wait for the search results to load\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Find image elements within the search results\n",
    "    image_elements = driver.find_elements(By.XPATH,'\"//*[@id=\"islrg\"]\"')\n",
    "\n",
    "    # Extract and print image URLs\n",
    "    print(f\"Image URLs for '{keyword}':\")\n",
    "    for img in image_elements[:10]:\n",
    "        print(img.get_attribute('src'))\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c807031",
   "metadata": {},
   "source": [
    "4. Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on www.flipkart.com\n",
    "and scrape following details for all the search results displayed on 1st page. Details to be scraped: “Brand\n",
    "Name”, “Smartphone name”, “Colour”, “RAM”, “Storage(ROM)”, “Primary Camera”,\n",
    "“Secondary Camera”, “Display Size”, “Battery Capacity”, “Price”, “Product URL”. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95497dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Navigate to Flipkart.com\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "\n",
    "# Wait for the login popup to load\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"_3skCyB\")))\n",
    "\n",
    "# Close the login popup\n",
    "driver.find_element(By.CLASS_NAME, \"_30XB9F\").click()\n",
    "\n",
    "# Search for the smartphone\n",
    "search_bar = driver.find_element(By.ID, \"fk-main-header-search-bar-search-box\")\n",
    "search_button = driver.find_element(By.CLASS_NAME, \"_34W8q1\")\n",
    "search= input('Enter brand name')\n",
    "search_bar.send_keys(search)\n",
    "search_button.click()\n",
    "\n",
    "# Wait for the search results to load\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//div[@class='_3we-t6']\")))\n",
    "\n",
    "# Get all the smartphone products on the 1st page\n",
    "products = driver.find_elements(By.XPATH, \"//div[@class='_3we-t6']\")\n",
    "\n",
    "# Scrape the smartphone details\n",
    "smartphone_details = []\n",
    "for product in products:\n",
    "    # Get the brand name\n",
    "    brand_name = search\n",
    "\n",
    "    # Get the smartphone name\n",
    "    smartphone_name = product.find_element(By.XPATH, \"//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[2]/div/div[1]/div/a[2]']\").text\n",
    "\n",
    "\n",
    "\n",
    "    # Get the RAM\n",
    "    ram = product.find_element(By.XPATH, \"//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[2]/div/div[1]/div/div[1]\").text\n",
    "\n",
    "    # Get the storage (ROM)\n",
    "    storage = product.find_element(By.XPATH, \".//div[@class='_21LHhT']/span\").text\n",
    "\n",
    "    # Get the price\n",
    "    price = product.find_element(By.XPATH, \"//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[2]/div/div[1]/div/a[3]/div/div[1]\").text\n",
    "\n",
    "    # Get the product URL\n",
    "    product_url = product.find_element(By.XPATH, \"//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[2]/div/div[1]/div/a[2]\").get_attribute(\"href\")\n",
    "\n",
    "    # Add the smartphone details to the list\n",
    "    smartphone_details.append({\n",
    "        \"Brand Name\": brand_name,\n",
    "        \"Smartphone Name\": smartphone_name,\n",
    "        \"RAM\": ram,\n",
    "        \"Price\": price,\n",
    "        \"Product URL\": product_url\n",
    "    })\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Save the smartphone details to a CSV file\n",
    "df = pd.DataFrame(smartphone_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d387239",
   "metadata": {},
   "source": [
    "5. Write a program to scrap geospatial coordinates (latitude, longitude) of a city searched on google maps. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b7b999",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "# Set up Chrome options\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')  # Run Chrome in headless mode (no GUI)\n",
    "\n",
    "\n",
    "# Create a new instance of the Chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open Google Maps\n",
    "driver.get('https://www.google.com/maps')\n",
    "\n",
    "# Find the search input and enter the city name\n",
    "search_input = driver.find_element(By.XPATH, '//input[@id=\"searchboxinput\"]')\n",
    "search_input.send_keys('mumbai')\n",
    "\n",
    "# Find and click the search button\n",
    "search_button = driver.find_element(By.XPATH, '//button[@id=\"searchbox-searchbutton\"]')\n",
    "search_button.click()\n",
    "\n",
    "# Wait for the map to load (you might need to adjust the sleep duration)\n",
    "time.sleep(2)\n",
    "\n",
    "# Extract geospatial coordinates\n",
    "# Find the coordinates element\n",
    "coordinates_element = driver.find_element(By.XPATH, '//meta[@itemprop=\"geo:position\"]')\n",
    "    \n",
    "# Get the content attribute, which contains the coordinates\n",
    "coordinates_content = coordinates_element.get_attribute('content')\n",
    "    \n",
    "# Split the coordinates into latitude and longitude\n",
    "latitude, longitude = map(float, coordinates_content.split(','))\n",
    "    \n",
    "print(f'Latitude: {latitude}, Longitude: {longitude}')\n",
    "\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0b47ea",
   "metadata": {},
   "source": [
    "7. Write a python program to scrape a data for all available Hostels from https://www.hostelworld.com/ in\n",
    "“London” location. You have to scrape hostel name, distance from city centre, ratings, total reviews, overall\n",
    "reviews, privates from price, dorms from price, facilities and property description. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aa83e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Navigate to the Hostelworld website\n",
    "driver.get(\"https://www.hostelworld.com/\")\n",
    "\n",
    "# Find the search input field, enter \"London\", and press Enter\n",
    "search_input = driver.find_element(\"id\", \"search-input-field\")\n",
    "search_input.send_keys(\"London\")\n",
    "search_input.send_keys(Keys.RETURN)\n",
    "\n",
    "# Wait for the search results to load\n",
    "time.sleep(2)\n",
    "\n",
    "# Extract the HTML content of the page\n",
    "html = driver.page_source\n",
    "\n",
    "# Parse the HTML content with BeautifulSoup\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Find all hostel containers on the page\n",
    "hostel_containers = soup.find_all(\"div\", class_=\"hostel-listing\")\n",
    "\n",
    "# Iterate through each hostel container and extract relevant information\n",
    "for hostel in hostel_containers:\n",
    "    hostel_name = hostel.find(\"h2\", class_=\"title\").text.strip()\n",
    "    distance = hostel.find(\"span\", class_=\"description\").text.strip()\n",
    "    rating = hostel.find(\"div\", class_=\"score\").text.strip()\n",
    "    total_reviews = hostel.find(\"div\", class_=\"reviews\").text.strip()\n",
    "    overall_reviews = hostel.find(\"div\", class_=\"keyword\").text.strip()\n",
    "    privates_price = hostel.find(\"div\", class_=\"price-col private-price\").text.strip()\n",
    "    dorms_price = hostel.find(\"div\", class_=\"price-col dorm-price\").text.strip()\n",
    "    facilities = [fac.text.strip() for fac in hostel.find_all(\"span\", class_=\"facilities-label\")]\n",
    "    description = hostel.find(\"div\", class_=\"rating-factors prop-card-tablet rating-factors small-12 columns\").text.strip()\n",
    "\n",
    "    # Print or store the extracted data as needed\n",
    "    print(f\"Hostel Name: {hostel_name}\")\n",
    "    print(f\"Distance from City Centre: {distance}\")\n",
    "    print(f\"Rating: {rating}\")\n",
    "    print(f\"Total Reviews: {total_reviews}\")\n",
    "    print(f\"Overall Reviews: {overall_reviews}\")\n",
    "    print(f\"Privates from Price: {privates_price}\")\n",
    "    print(f\"Dorms from Price: {dorms_price}\")\n",
    "    print(f\"Facilities: {', '.join(facilities)}\")\n",
    "    print(f\"Property Description: {description}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f8d4f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
