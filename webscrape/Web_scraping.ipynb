{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1) Write a python program to display all the header tags from wikipedia.org and make data frame.\n"
      ],
      "metadata": {
        "id": "5kAMg7NMlODF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Send an HTTP GET request to Wikipedia\n",
        "response = requests.get(\"https://en.wikipedia.org/wiki/Main_Page\")\n",
        "\n",
        "# Parse the HTML content of the page\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Extract and display all header tags\n",
        "headers = [header.text for header in soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])]\n",
        "\n",
        "data = {'Headers': headers}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the data frame\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXkMLr7Vk347",
        "outputId": "40801af7-af6e-4285-fa64-e129d8b7291b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                          Headers\n",
            "0                       Main Page\n",
            "1            Welcome to Wikipedia\n",
            "2   From today's featured article\n",
            "3                Did you know ...\n",
            "4                     In the news\n",
            "5                     On this day\n",
            "6      From today's featured list\n",
            "7        Today's featured picture\n",
            "8        Other areas of Wikipedia\n",
            "9     Wikipedia's sister projects\n",
            "10            Wikipedia languages\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Write s python program to display list of respected former presidents of India(i.e. Name , Term ofoffice)\n",
        "from https://presidentofindia.nic.in/former-presidents.html and make data frame.\n",
        "\n",
        "Note: Page not found"
      ],
      "metadata": {
        "id": "SmXp7nB-lX3S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame\n",
        "a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
        "b) Top 10 ODI Batsmen along with the records of their team andrating.\n",
        "c) Top 10 ODI bowlers along with the records of their team andrating.\n"
      ],
      "metadata": {
        "id": "rJpcNwohphEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# URLs for ODI teams, batsmen, and bowlers rankings\n",
        "odi_teams_url = \"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\"\n",
        "odi_batsmen_url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\"\n",
        "odi_bowlers_url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\"\n",
        "\n",
        "# Function to scrape rankings data and create a DataFrame\n",
        "def scrape_icc_rankings(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Find the table containing the data\n",
        "    table = soup.find('table', class_='table')\n",
        "\n",
        "    if table:\n",
        "        data = []\n",
        "        rows = table.find_all('tr')\n",
        "        for row in rows[1:11]:  # Get the top 10 rows (excluding the header)\n",
        "            columns = row.find_all('td')\n",
        "            record = {\n",
        "                \"Rank\": columns[0].text.strip(),\n",
        "                \"Name\": columns[1].text.strip(),\n",
        "                \"Matches\": columns[2].text.strip(),\n",
        "                \"Points\": columns[3].text.strip(),\n",
        "                \"Rating\": columns[4].text.strip(),\n",
        "            }\n",
        "            data.append(record)\n",
        "\n",
        "        df = pd.DataFrame(data)\n",
        "        return df\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Scrape data and create data frames\n",
        "odi_teams_df = scrape_icc_rankings(odi_teams_url)\n",
        "odi_batsmen_df = scrape_icc_rankings(odi_batsmen_url)\n",
        "odi_bowlers_df = scrape_icc_rankings(odi_bowlers_url)\n",
        "\n",
        "print(\"Top 10 ODI Teams:\")\n",
        "print(odi_teams_df)\n",
        "\n",
        "print(\"\\nTop 10 ODI Batsmen:\")\n",
        "print(odi_batsmen_df)\n",
        "\n",
        "print(\"\\nTop 10 ODI Bowlers:\")\n",
        "print(odi_bowlers_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_wePXV87hh0",
        "outputId": "c7911dc7-a95f-4212-971d-fa003eea773a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 ODI Teams:\n",
            "  Rank              Name Matches Points Rating\n",
            "0    1        India\\nIND      49  5,839    119\n",
            "1    2    Australia\\nAUS      36  4,015    112\n",
            "2    3     Pakistan\\nPAK      32  3,525    110\n",
            "3    4  South Africa\\nSA      29  3,166    109\n",
            "4    5   New Zealand\\nNZ      38  4,007    105\n",
            "5    6      England\\nENG      34  3,377     99\n",
            "6    7     Sri Lanka\\nSL      43  3,943     92\n",
            "7    8   Bangladesh\\nBAN      40  3,574     89\n",
            "8    9  Afghanistan\\nAFG      26  2,170     83\n",
            "9   10   West Indies\\nWI      38  2,582     68\n",
            "\n",
            "Top 10 ODI Batsmen:\n",
            "                                                Rank                   Name  \\\n",
            "0               1\\n                        \\n\\n\\n(0)             Babar Azam   \n",
            "1       2\\n                                \\n\\n\\n(0)           Shubman Gill   \n",
            "2  3\\n                                \\n\\n\\n\\n\\n(...        Quinton de Kock   \n",
            "3  4\\n                                \\n\\n\\n\\n\\n(...       Heinrich Klaasen   \n",
            "4  5\\n                                \\n\\n\\n\\n\\n(...           David Warner   \n",
            "5  =\\n                                \\n\\n\\n\\n\\n(...            Virat Kohli   \n",
            "6       7\\n                                \\n\\n\\n(0)           Harry Tector   \n",
            "7  8\\n                                \\n\\n\\n\\n\\n(...           Rohit Sharma   \n",
            "8  9\\n                                \\n\\n\\n\\n\\n(...  Rassie van der Dussen   \n",
            "9      10\\n                                \\n\\n\\n(0)            Imam-ul-Haq   \n",
            "\n",
            "  Matches Points                         Rating  \n",
            "0     PAK    829  898 v West Indies, 10/06/2022  \n",
            "1     IND    823    847 v Australia, 24/09/2023  \n",
            "2      SA    769    813 v Sri Lanka, 10/03/2019  \n",
            "3      SA    756   756 v Bangladesh, 24/10/2023  \n",
            "4     AUS    747     880 v Pakistan, 26/01/2017  \n",
            "5     IND    747      911 v England, 12/07/2018  \n",
            "6     IRE    729      729 v England, 23/09/2023  \n",
            "7     IND    725    885 v Sri Lanka, 06/07/2019  \n",
            "8      SA    716      796 v England, 19/07/2022  \n",
            "9     PAK    704  815 v West Indies, 12/06/2022  \n",
            "\n",
            "Top 10 ODI Bowlers:\n",
            "                                                Rank            Name Matches  \\\n",
            "0               1\\n                        \\n\\n\\n(0)  Josh Hazlewood     AUS   \n",
            "1       2\\n                                \\n\\n\\n(0)  Mohammed Siraj     IND   \n",
            "2  3\\n                                \\n\\n\\n\\n\\n(...  Keshav Maharaj      SA   \n",
            "3  4\\n                                \\n\\n\\n\\n\\n(...     Rashid Khan     AFG   \n",
            "4  5\\n                                \\n\\n\\n\\n\\n(...     Trent Boult      NZ   \n",
            "5  6\\n                                \\n\\n\\n\\n\\n(...   Mohammad Nabi     AFG   \n",
            "6  7\\n                                \\n\\n\\n\\n\\n(...      Adam Zampa     AUS   \n",
            "7  8\\n                                \\n\\n\\n\\n\\n(...      Matt Henry      NZ   \n",
            "8       9\\n                                \\n\\n\\n(0)   Kuldeep Yadav     IND   \n",
            "9      10\\n                                \\n\\n\\n(0)  Shaheen Afridi     PAK   \n",
            "\n",
            "  Points                          Rating  \n",
            "0    670       733 v England, 26/01/2018  \n",
            "1    668   736 v New Zealand, 21/01/2023  \n",
            "2    656    656 v Bangladesh, 24/10/2023  \n",
            "3    654      806 v Pakistan, 21/09/2018  \n",
            "4    653     775 v Australia, 11/09/2022  \n",
            "5    641      657 v Zimbabwe, 09/06/2022  \n",
            "6    635  670 v South Africa, 09/09/2023  \n",
            "7    634    691 v Bangladesh, 26/03/2021  \n",
            "8    632   765 v New Zealand, 26/01/2019  \n",
            "9    625   688 v West Indies, 10/06/2022  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data framea) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
        "b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
        "c) Top 10 women’s ODI all-rounder along with the records of their team and rating."
      ],
      "metadata": {
        "id": "OTCC_o0R8SWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# URLs for ODI teams, women's ODI batting players, and women's ODI all-rounders rankings\n",
        "odi_womens_teams_url = \"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\"\n",
        "odi_womens_batting_url = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\"\n",
        "odi_womens_allrounder_url = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\"\n",
        "\n",
        "# Function to scrape rankings data and create a DataFrame\n",
        "def scrape_icc_rankings(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Find the table containing the data\n",
        "    table = soup.find('table', class_='table')\n",
        "\n",
        "    if table:\n",
        "        data = []\n",
        "        rows = table.find_all('tr')\n",
        "        for row in rows[1:11]:  # Get the top 10 rows (excluding the header)\n",
        "            columns = row.find_all('td')\n",
        "            record = {\n",
        "                \"Rank\": columns[0].text.strip(),\n",
        "                \"Name\": columns[1].text.strip(),\n",
        "                \"Team\": columns[2].text.strip(),\n",
        "                \"Rating\": columns[3].text.strip(),\n",
        "            }\n",
        "            data.append(record)\n",
        "\n",
        "        df = pd.DataFrame(data)\n",
        "        return df\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Scrape data and create data frames\n",
        "odi_womens_teams_df = scrape_icc_rankings(odi_womens_teams_url)\n",
        "odi_womens_batting_df = scrape_icc_rankings(odi_womens_batting_url)\n",
        "odi_womens_allrounder_df = scrape_icc_rankings(odi_womens_allrounder_url)\n",
        "\n",
        "# Display the data frames\n",
        "print(\"Top 10 Women's ODI Teams:\")\n",
        "print(odi_womens_teams_df)\n",
        "\n",
        "print(\"\\nTop 10 Women's ODI Batting Players:\")\n",
        "print(odi_womens_batting_df)\n",
        "\n",
        "print(\"\\nTop 10 Women's ODI All-rounders:\")\n",
        "print(odi_womens_allrounder_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6eQaJpX-qpj",
        "outputId": "91121c19-9992-4096-9f13-bc7e7ad98e34"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 Women's ODI Teams:\n",
            "  Rank              Name Team Rating\n",
            "0    1    Australia\\nAUS   19  3,084\n",
            "1    2      England\\nENG   23  2,991\n",
            "2    3  South Africa\\nSA   21  2,446\n",
            "3    4        India\\nIND   18  1,745\n",
            "4    5   New Zealand\\nNZ   21  2,014\n",
            "5    6   West Indies\\nWI   18  1,610\n",
            "6    7     Sri Lanka\\nSL    9    714\n",
            "7    8   Bangladesh\\nBAN   11    816\n",
            "8    9     Thailand\\nTHA   11    753\n",
            "9   10     Pakistan\\nPAK   21  1,435\n",
            "\n",
            "Top 10 Women's ODI Batting Players:\n",
            "                                            Rank                  Name Team  \\\n",
            "0           1\\n                        \\n\\n\\n(0)  Natalie Sciver-Brunt  ENG   \n",
            "1   2\\n                                \\n\\n\\n(0)           Beth Mooney  AUS   \n",
            "2   3\\n                                \\n\\n\\n(0)   Chamari Athapaththu   SL   \n",
            "3   4\\n                                \\n\\n\\n(0)       Laura Wolvaardt   SA   \n",
            "4   5\\n                                \\n\\n\\n(0)       Smriti Mandhana  IND   \n",
            "5   6\\n                                \\n\\n\\n(0)          Alyssa Healy  AUS   \n",
            "6   7\\n                                \\n\\n\\n(0)          Ellyse Perry  AUS   \n",
            "7   8\\n                                \\n\\n\\n(0)      Harmanpreet Kaur  IND   \n",
            "8   9\\n                                \\n\\n\\n(0)           Meg Lanning  AUS   \n",
            "9  10\\n                                \\n\\n\\n(0)        Marizanne Kapp   SA   \n",
            "\n",
            "  Rating  \n",
            "0    807  \n",
            "1    750  \n",
            "2    736  \n",
            "3    727  \n",
            "4    708  \n",
            "5    698  \n",
            "6    697  \n",
            "7    694  \n",
            "8    662  \n",
            "9    642  \n",
            "\n",
            "Top 10 Women's ODI All-rounders:\n",
            "                                            Rank                  Name Team  \\\n",
            "0           1\\n                        \\n\\n\\n(0)        Marizanne Kapp   SA   \n",
            "1   2\\n                                \\n\\n\\n(0)      Ashleigh Gardner  AUS   \n",
            "2   3\\n                                \\n\\n\\n(0)  Natalie Sciver-Brunt  ENG   \n",
            "3   4\\n                                \\n\\n\\n(0)       Hayley Matthews   WI   \n",
            "4   5\\n                                \\n\\n\\n(0)           Amelia Kerr   NZ   \n",
            "5   6\\n                                \\n\\n\\n(0)         Deepti Sharma  IND   \n",
            "6   7\\n                                \\n\\n\\n(0)          Ellyse Perry  AUS   \n",
            "7   8\\n                                \\n\\n\\n(0)         Jess Jonassen  AUS   \n",
            "8   =\\n                                \\n\\n\\n(0)         Sophie Devine   NZ   \n",
            "9  10\\n                                \\n\\n\\n(0)              Nida Dar  PAK   \n",
            "\n",
            "  Rating  \n",
            "0    385  \n",
            "1    377  \n",
            "2    360  \n",
            "3    358  \n",
            "4    346  \n",
            "5    312  \n",
            "6    282  \n",
            "7    227  \n",
            "8    227  \n",
            "9    224  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world and\n",
        "make data framei) Headline\n",
        "ii) Time\n",
        "iii) News Link"
      ],
      "metadata": {
        "id": "Y4uqVR13-ogP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://www.cnbc.com/world/?region=world\"\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "data = {'Headline': [], 'Time': [], 'News Link': []}\n",
        "\n",
        "articles = soup.find_all('div', class_='RiverHeadline-headline RiverHeadline-hasThumbnail')\n",
        "\n",
        "for article in articles:\n",
        "    # Extract headline\n",
        "    headline = article.find('h3', class_='RiverHeadline-headline RiverHeadline-hasThumbnail')\n",
        "    headline_text = headline.text.strip() if headline else 'N/A'\n",
        "    data['Headline'].append(headline_text)\n",
        "\n",
        "    # Extract time\n",
        "    time_element = article.find('time')\n",
        "    time = time_element['datetime'] if time_element else 'N/A'\n",
        "    data['Time'].append(time)\n",
        "\n",
        "    # Extract news link\n",
        "    link_element = article.find('a', class_='RiverHeadline-headline RiverHeadline-hasThumbnail')\n",
        "    link = link_element['href'] if link_element else 'N/A'\n",
        "    data['News Link'].append(link)\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the data frame\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zc7KznUG96Wx",
        "outputId": "e465828a-dbae-4a82-81f6-92475de952c4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Headline Time News Link\n",
            "0       N/A  N/A       N/A\n",
            "1       N/A  N/A       N/A\n",
            "2       N/A  N/A       N/A\n",
            "3       N/A  N/A       N/A\n",
            "4       N/A  N/A       N/A\n",
            "5       N/A  N/A       N/A\n",
            "6       N/A  N/A       N/A\n",
            "7       N/A  N/A       N/A\n",
            "8       N/A  N/A       N/A\n",
            "9       N/A  N/A       N/A\n",
            "10      N/A  N/A       N/A\n",
            "11      N/A  N/A       N/A\n",
            "12      N/A  N/A       N/A\n",
            "13      N/A  N/A       N/A\n",
            "14      N/A  N/A       N/A\n",
            "15      N/A  N/A       N/A\n",
            "16      N/A  N/A       N/A\n",
            "17      N/A  N/A       N/A\n",
            "18      N/A  N/A       N/A\n",
            "19      N/A  N/A       N/A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6) Write a python program to scrape the details of most downloaded articles from AI in last 90\n",
        "days.https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
        "Scrape below mentioned details and make data framei) Paper Title\n",
        "ii) Authors\n",
        "iii) Published Date\n",
        "iv) Paper URL"
      ],
      "metadata": {
        "id": "Rzz1O9qs-eEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Send an HTTP GET request to the website\n",
        "url = \"https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\"\n",
        "response = requests.get(url)\n",
        "\n",
        "# Parse the HTML content of the page\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Find the list of articles\n",
        "articles = soup.find_all('div', class_='sc-orwwe2-3 jOMrrY')\n",
        "\n",
        "# Initialize lists to store the data\n",
        "titles = []\n",
        "authors = []\n",
        "dates = []\n",
        "urls = []\n",
        "\n",
        "# Extract the data\n",
        "for article in articles:\n",
        "    # Extract paper title\n",
        "    title_element = article.find('a', class_='sc-5smygv-0 fIXTHm')\n",
        "    title = title_element.text.strip() if title_element else \"N/A\"\n",
        "    titles.append(title)\n",
        "\n",
        "    # Extract authors\n",
        "    authors_element = article.find('span', class_='sc-1w3fpd7-0 dnCnAO')\n",
        "    author = authors_element.text.strip() if authors_element else \"N/A\"\n",
        "    authors.append(author)\n",
        "\n",
        "    # Extract published date\n",
        "    date_element = article.find('span', class_='sc-1thf9ly-2 dvggWt')\n",
        "    date = date_element.text.strip() if date_element else \"N/A\"\n",
        "    dates.append(date)\n",
        "\n",
        "    # Extract paper URL\n",
        "    url_element = article.find('a', class_='sc-5smygv-0 fIXTHm')\n",
        "    url = url_element['href'] if url_element else \"N/A\"\n",
        "    urls.append(url)\n",
        "\n",
        "# Create a data frame\n",
        "data = {\n",
        "    'Paper Title': titles,\n",
        "    'Authors': authors,\n",
        "    'Published Date': dates,\n",
        "    'Paper URL': urls\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the data frame\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DboAv273_oMj",
        "outputId": "a675946b-4979-4043-890b-616f0a5ba580"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Paper Title                                            Authors  \\\n",
            "0  Reward is enough  David Silver, Satinder Singh, Doina Precup, Ri...   \n",
            "\n",
            "  Published Date                                          Paper URL  \n",
            "0   October 2021  https://www.sciencedirect.com/science/article/...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a python program to scrape mentioned details from dineout.co.inand make data framei) Restaurant name\n",
        "ii) Cuisine\n",
        "iii) Location\n",
        "iv) Ratings\n",
        "v) Image URL"
      ],
      "metadata": {
        "id": "DjtIJiSvAqh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Send an HTTP GET request to the website\n",
        "url = \"https://www.dineout.co.in/delhi-restaurants\"\n",
        "response = requests.get(url)\n",
        "\n",
        "# Parse the HTML content of the page\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Find the list of restaurants\n",
        "restaurants = soup.find_all('div', class_='_32KKc')\n",
        "\n",
        "# Initialize lists to store the data\n",
        "restaurant_names = []\n",
        "ratings = []\n",
        "image_urls = []\n",
        "\n",
        "# Extract the data\n",
        "for restaurant in restaurants:\n",
        "    # Extract restaurant name\n",
        "    name_element = restaurant.find(\"h4\", class_='_1jbOb')\n",
        "    name = name_element.text.strip() if name_element else \"N/A\"\n",
        "    restaurant_names.append(name)\n",
        "\n",
        "    # Extract ratings\n",
        "    rating_element = restaurant.find('div', class_='kGUdK _1oTbl')\n",
        "    rating = rating_element.text.strip() if rating_element else \"N/A\"\n",
        "    ratings.append(rating)\n",
        "\n",
        "    # Extract image URL\n",
        "    image_element = restaurant.find('img')\n",
        "    image_url = image_element['src'] if image_element else \"N/A\"\n",
        "    image_urls.append(image_url)\n",
        "\n",
        "# Create a data frame\n",
        "data = {\n",
        "    'Restaurant Name': restaurant_names,\n",
        "    'Ratings': ratings,\n",
        "    'Image URL': image_urls\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the data frame\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYvJea93AR6G",
        "outputId": "617ea60f-9243-402c-b452-bed23db6b246"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [Restaurant Name, Ratings, Image URL]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IQc6nCPFBsSH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}